# 캐시 메모리(Cache Memory)
속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터는 캐시 메모리에 저장하여 다음에 이용할 때는 주기억장치에 접근하지 않고 캐시 메모리에서 먼저 가져와 속도를 향상시킨다.

하나의 CPU에는 이러한 캐시 메모리가 2~3개 정도 사용되며 L1, L2, L3 캐시 메모리라고 부른다.
속도와 크기에 따라 분류한 것으로 일반적으로 가장 빠르게 접근 가능한 L1 캐시부터 사용된다.

### 캐시 메모리 작동 원리
참조 지역성의 원리
- 시간 지역성
for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음.
- 공간 지역성
A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음.

캐시에 데이터를 저장할 때는, 이러한 참조 지역성(공간)을 최대한 활용하기 위해 해당 데이터뿐만 아니라, 옆 주소의 데이터도 같이 가져와 미래에 쓰일 것을 대비한다.

CPU가 요청한 데이터가 캐시에 있으면 'Cache Hit', 없어서 DRAM에서 가져오면 'Cache Miss'라고 한다.

### Cache Miss 3가지 경우
1. Cold miss - 해당 메모리 주소를 처음 불러서 나는 미스
2. Conflict miss - 캐시 메모리에 A와 B 데이터를 저장해야 하는데, A와 B가 같은 캐시 메모리 주소에 할당되어 있어서 나는 미스 (direct mapped cache에서 많이 발생)
3. Capacity miss - 캐시 메모리의 공간이 부족해서 나는 미스 (Conflict는 주소 할당 문제, Capacity는 공간 문제)

캐시 크기를 키워서 문제를 해결하려면 캐시 접근 속도가 느려지고 파워를 많이 먹는 단점이 생긴다.
