# ✏ LeetCode - Machine Learning 101
리트 코드의 머신러닝 관련 영문 자료를 읽고 정리하였다. 
'what'은 그 첫번째 챕터로 머신러닝이란 무엇인지에 대해 나와있다.

## 📔 Machine Learning - what
"Machine Learning"의 단어는 machine이 사람처럼 학습하거나 사람보다 더 잘 학습한다는 느낌이 들어 컴퓨터 과학의 본질을 신비화하는 경향이 있다. 

그러나 머신 러닝은 미리 정의된 절차를 수행하는 컴퓨터 프로그램에 지나지 않는다.
머신러닝 알고리즘과 논-머신러닝 알고리즘을 구분하는 기준은 새로운 입력에 적응시키는 동작이다.
여기서 적응은, 사람의 개입 없이 machine(program)이 스스로 학습하는 것 같은 인상을 준다.
그러나 머신러닝 모델 아래에는 적응의 동작들은 모두 엄격한 사람이 프로그래밍 해 놓은 명령들이다.  

### 🤖그렇다면 머신러닝 모델이란 무엇인가?
> 머신러닝 알고리즘은 데이터 속에 잠재된 관계를 찾아내는 프로세스다.
머신러닝 알고리즘의 결과는 머신러닝 모델이라고 불리는데 입력값에 대한 특정한 결과를 얻을 수 있는 함수와 같다.
함수를 정의하고 수정하는 것이 아닌, 머신러닝 모델은 과거 데이터에 기인한다.
그러므로, 우리는 다른 데이터를 줌으로써, 머신러닝 알고리즘의 결과를 바꿀 수 있고, 머신러닝 모델 또한 바뀌는 것이다.

예를 들어보자.
이미지 인식이라는 시나리오에서 누군가 머신러닝 모델에게 object의 사진들을 주고 구별하게 할 것이다.
머신러닝 알고리즘에 고양이가 있는 사진들과 없는 사진들 수천개를 줘서 사진 속에 고양이가 있는지 없는지 말해줄 수 있는 모델을 얻는다고 가정해보자. 그 결과로 생성된 모델의 입력값은 디지털 사진일 것이고, 출력값은 사진 속 고양이 유무에 대한 불린값이 될 것이다.
![](https://velog.velcdn.com/images/lhj99apr/post/fc338def-a6dd-4f02-a8f1-9c1ea219e120/image.png)


위 케이스의 머신러닝 모델은 다차원의 픽셀 값들을 이진 값으로 매칭하는 함수인 것이다.
우리가 3픽셀의 사진을 가지고 있다고 가정해보자, 그리고 각각의 픽셀 값의 범위는 0-255이다.
그럼 입력값과 출력값 사이의 mapping space는 (256x256x256)x2, 약 3300만이다.
게다가 실제 세상에서의 일반적인 사진들은 수백만 픽셀값, 각 픽셀값은 3개의 색(RGB)로 이루어져 있기 때문에, 이러한 머신러닝 모델의 mapping은 엄청난 테스크라는 것을 알 수 있다.

> 머신러닝의 테스크는 방대한 mapping space의 함수를 학습하는 것이다.

이미지 인식 외에도 다른 많은 케이스가 있지만, 이미지 인식의 케이스에서는 수백만의 픽셀과 yes/no의 정답 사이에 숨어있는 mapping 관계를 찾아내는 과정을 머신러닝이라고 말한다. 
대부분 우리가 마지막에 얻는 건 내재된 관계의 근사치가 될 것이다.
어디까지나 근사치이기 때문에, 누군가는 머신러닝 모델의 결과의 정확도가 100%가 아니라는 것에 실망할 지 모른다.
2012년, 딥러닝 기술의 확장이 일어나기 전에는 가장 최고의 머신러닝 모델은 약 75%의 정확도를 가지고 있었다. 지금까지도 100%의 정확도를 가진 머신 러닝 모델은 없지만, 현재 모델들은 사람의 일에 비교해 5퍼센트 이하의 적은 에러율을 달성하게 되었다.

-----

### 📔 Supervised VS. Unsupervised

위에서는 머신러닝의 정의에 대해 간단하게 알아보았고, 이번에는 더 구체적으로 개념을 공부해보자!

먼저 머신러닝 문제가 주어지면 가장 먼저 supervised / unsupervised 중 어떤 문제인지 결정할 것이다.
많은 머신러닝 문제들은 샘플 데이터 묶음인 데이터 셋으로부터 시작하는데, 각각의 샘플들은 속상 값들의 튜플로 나타날 것이다.

예를 들어, 머신러닝을 공부했다면 몇번이고 봤을 "분류학적 문제에서 다중 측정의 사용" 논문에 나왔던 Iris 데이터셋을 살펴보자.
Iris 데이터는 붓꽃 150개의 측정값 샘플로 이루어진 데이터인데, 각각의 샘플은 붓꽃을 'setosa, versicolor, virginica 라는 세가지 분류로 나누는 특징인 꽃잎과 꽃받침의 길이와 넓이 값으로 이루어져 있다.
아래의 데이터 셋의 샘플 일부를 확인해보자. 
![img](https://velog.velcdn.com/images/lhj99apr/post/295437d0-1d9a-44b3-b098-940f23582686/image.png)

**< Supervised Learning >**
Supervised Learning(지도학습) 테스크는 데이터 샘플은 타켓 속성이자 실제 정답인 y 값을 포함하고 있다. 함수 F를 학습하기 위해 x라는 속성값들을 받고 결과로 타켓 값에 근사치인 y값들을 출력한다. 즉, 여기의 y 값들은 학습 과정에서 결과의 벤치마크로 주어지는 가이드가 되며, 이러한 테스크를 지도학습이라고 한다.

**< Unsupervised Learning >**
Unsupervised Learning(비지도학습)은 지도학습과 달리 실측 정보가 없다. 벤치마크할 사전 정의된 자료가 없기 때문에 데이터에서 기본 패턴이나 규칙을 학습해야 한다.
실제 값의 가이드가 없이 학습할 수 있을지 궁금할 것이다. 몇가지 예를 보겠다.

> 클러스터링
데이터 세트나 주어지면 그 데이터들 사이의 유사성을 기반으로 여러 개의 그룹으로 클러스터링할 수 있다. 예를 들어보면 구매한 항목 수, 쇼핑 사이트에서 보낸 시간 등의 속상을 가진 고객 프로필 ㄷ이터들이 있을 있다. 이러한 속성들을 가지고 유사한 고객 프로필끼리 그룹을 묶을 수 있고, 이 클러스터링 된 결과를 사용하면, 각 그룹을 대상으로 할 적합한 상업 캠페인을 고안할 수 있고, 고객 유치와 유지에 도움을 얻을 수 있다.

> 연결 패턴
데이터 세트가 주어지면 데이터 속상 간의 숨겨진 연결 패턴을 발견할 수 이싿. 예를 들어, 샘플은 고객의 장바구니라고 했을 때, 샘플의 각 속성은 상품 목록이 될 것이다. 여기서 맥주를 구입한 고객이 종종 기저귀도 함께 구입했다는 패턴이 발견된다면 둘 사이에는 연관성이 있다고 볼 수 있다. 이런 학습 결과로 얻은 통찰력으로 밀접하게 관련된 상품을 가까운 코너로 배치한다던지 전략을 세워 판매를 촉진할 수 있다.

**< Semi-supervised Learning >**
Semi-supervised Learning(준지도학습)
크기는 방대하지만 레이블이 적은 데이터 세트는 지도학습과 비지도학습을 모두 적용할 수 있다. 이것을 준지도학습이라고 한다. 실제로 많은 속성(레이블)을 가진 데이터를 구축하기 위해서는 많은 시간과 비용, 수동 작업이 필요하다. 그래서 범주나 제목이 없는 비디오 수만개와 같이 정확한 레이블이 지정되어 있지 않은 데이터가 거의 없는 경우가 많다.
레이블이 거의 없는 데잉터 세트에서는 지도학습과 비지도학습을 결합하여 데이터 세트를 더 확장할 수 있기 때문에, 개별적으로 데이터를 적용하는 것보다 더 좋은 결과를 얻을 수 있다.

예를 들어 이미지의 레이블을 예측하고 싶은데 10%의 사진만 레이블이 있다고 한다면 지도학습을 적용하여 레이블이 있는 데이터로 학습을 한 후, 다른 레이블이 없는 데이터에 적용하여 임시 레이블을 달아줄 수 있다. 여기서 소수의 데이터로만 학습했기 때문에 모델이 일반적으로 잘 학습했을 거라는 확신이 들지 않을 것이다. 그럴 때 먼저 모든 데이터들을 그룹으로 비지도학습의 방법인 클러스터링을 한 다음, 각 그룹에 개별적으로 지도학습 알고리즘을 적용하면 앞서 했던 단순 지도학습보다 더 나은 정확도를 얻을 수 있을 것이다.


[참조논문]
[1]. Fisher,RA " 분류학적 문제에서 다중 측정의 사용 " Annual Eugenics, 7, Part II, 179-188 (1936)

<br>

### Classification VS. Regreesion
앞에서는 특정 input과 output을 갖는 함수로써 머신러닝 모델을 정의했다. 
우리는 output 값들의 유형에 따라 분류와 회귀로 머신러닝 모델을 구분하기도 한다.

> 만약 머신러닝 모델의 결과값이 0/1 과 같은 분리된 값이라면 우리는 그것을 분류 모델이라고 한다. 반면에 모델의 결과값이 연속적인 값이라면 회귀 모델이라고 부른다.

**Classification Model(분류 모델)**
예를 들어, 고양이가 사진에 있는지 없는지 말해주는 모델은 결과값이 boolean = 이진값이기 때문에 분류 모델이라고 할 수 있다. 
![img](https://velog.velcdn.com/images/lhj99apr/post/1b87e266-2e25-4d6c-b3ba-6e99d9d34615/image.png)

더 자세하게 말하면, 입력값은 H(사진의 높이 픽셀값) x W(사진의 넓이 픽셀값) 차원을 가지는 행렬 M이다. 행렬 M의 각각의 요소들은 사진 속 각각의 픽셀의 그레이스케일 값이고 [0,255] 사이의 색상의 강도를 나타낸다. 모델의 예상 출력 값은 이진값으로 0과 1로 사진에 고양이가 있는지 여부를 나타낸다.
요약을 하자면 고양이 사진 인식 모델의 함수 F는 다음과 같은 공식으로 표현할 수 있다.

F(M[H][W])=1∣0, where M[i][j]∈[0,255], 0<i<H,0<j<w. 

그리고 머신러닝의 목표는 가능한 일반적인 함수를 찾는 것으로, 보이지 않는 데이터에 옳은 답을 줄 확률이 높은 함수를 발견하는 것이다.

**Regression Model(회귀 모델)**
회귀 모델의 예로써, 표면적인 특징들, 부동산 유형과 위치와 같은 특성을 고려해 부동산 값을 예측하는 모델을 말할 수 있다. 이런 경우에, 우리는 결과값으로 실제 값 p∈R 회귀 모델의 예상 범주에 속할 것을 기대한다. 예에서 우리가 가지고 있는 원시 데이터는 모두 숫자가 아니지만 일부는 부동산 유형과 같은 분류를 가지며 이런 케이스가 실제 현실의 문제와 비슷하다.


각각의 부동산에는 그것의 특징들을 튜플 T로 표현할 수 있고, 튜플의 각각의 요소들은 수치 값이나 카테고리 값이다. 그 요소들은 많은 케이스에서 features 라고 부르며 요약하자면 우리는 우리의 부동산 값 예측 모델을 아래처럼 공식화할 수 있다.
> F(T)=p, where p∈R

더 자세히 살펴보기 위해 다음과 같은 특징을 가진 부동산을 고려해보자
surface = 120 m^2 , type = 'apartment' , location = 'NY downtown', year_of_construction = 2000

위의 특징이 주어졌을 때, 우리의 모델 F가 10,000 달러의 값을 준다면 이 문제에 우리의 모델이 적합하지 않아 보인다.
예를 들어 다음 그래프를 보면 부동산의 표면을 유일한 변수로 부동산 가격을 출력하는 회귀 모델이다.
![img](https://velog.velcdn.com/images/lhj99apr/post/68a45cf5-c609-4f6c-95fe-c78a01369e82/image.png)
일부 머신러닝 모델은 숫자가 아닌 기능을 있는 그대로 직접 처리할 수 있는 한편, 더 자주 비 숫자 기능을 숫자로 처리해야 한다는 점을 언급하고 싶다.


**Problem Conversion(문제 변환)**

실제 세상의 문제가 주어지면 가금 누군가는 그걸 쉽게 공식화하여 빠르게 분류문제/회귀문제로 특징한다. 하지만 가끔은 이 두 모델의 경계가 불분명하므로, 분류 문제에서 회귀 문제로, 혹은 그 반대로 변환하기도 한다.

위의 부동산 가격 예측 예시를 보더라도, 실제 정확한 부동산 값을 예측하는 것은 어렵게 보인다. 하지만 단순 가격 태크가 아니라, 가격 예상 범위를 예측하는 문제로 재정의한다면 더 강력한 모델을 얻을 수 있지 않을까? 결론적으로, 우리는 문제를 회귀가 아닌 분류 문제로 변환할 수 있다.

고양이 사진 인식 모델에서도 우리는 분류 모델을 회귀 모델로 변환할 수 있다.
결과를 이진값으로 주는 것이 아닌, 고양이가 있을 확률을 0-100% 사이의 값으로 주는 모델로 정의할 수 있다.
이 방법은 모델 사이의 작은 차이를 비교하고 더 나아가 모델을 조정할 수 있다.
예를 들어, 고양이가 있는 사진을 모델 A가 1%의 확률을 주었고, 반면 모델 B는 같은 사진에 49%의 확률을 주었다고 하자. 두 모델은 둘다 정답을 주는 데에는 실패했을지만, B 모델이 사실에 더 가까운 답을 말했다. 
이런 시나리오에서 우리는 로지스틱 회귀라고 물리는 머신러닝 모델을 적용하여, 연속된 확률의 출력값을 분류 문제로 풀 수 있도록 한다.