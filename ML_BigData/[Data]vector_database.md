# Vector Database
### 벡터 데이터베이스란?
방대한 양의 고차원 데이터를 벡터 형태로 최적화하여 보관하고 쿼리하기 위해 특화된 DB로 입력된 데이터가 임베딩 모델을 거쳐 벡터화되어 저장된다.    
임베딩 기술로 생성된 고차원 벡터는 중요한 정보를 유지하면서 복잡한 데이터 항목을 수치로 변환하여 저장한다. 따라서 벡터 데이터베이스는 벡터 임베딩 구조를 수용할 수 있도록 구축되었고 인덱싱 알고리즘을 
사용해서 쿼리 벡터와의 유아성을 기반으로 효과적으로 검색한다.   

일반적인 파이프라인은 아래와 같이 진행된다.    
![img](https://d33wubrfki0l68.cloudfront.net/d6193189ca227649e88e3da51b79002e3c88b97e/14289/images/what-is-a-vector-db/pipeline.png)

- Indexing: 벡터 데이터베이스는 PQ, LSH 또는 HNSW와 같은 알고리즘을 사용하여 벡터를 인덱싱한다. 이 단계는 더 빠른 검색을 가능하게 하는 데이터 구조에 벡터를 매핑한다.   
- Querying: 벡터 데이터베이스는 가장 가까운 이웃을 찾기 위해 인덱스 쿼리 벡터를 데이터 세트의 인덱스 벡터와 비교한다.   
- Post Processing: 경우에 따라 벡터 데이터베이스는 데이터 세트에서 가장 가까운 최종 이웃을 검색하고 사후 처리하여 최종 결과를 반환한다. 


## 벡터 인덱스 생성 알고리즘
* Random Projection(무작위 투영)   
무작위 투영 행렬을 사용해 고차원 벡터를 유사성을 유지한 채 저차원 공간에 투영하는 방법이다. 먼저 우리가 원하는 목표 차원을 가지는 난수 행렬을 만들고 입력 벡터와 행렬의 내적을 계산하여 차원은 작아지되 유사성을 유지하는 투영 행렬을 구할 수 있다.   
![img](https://d33wubrfki0l68.cloudfront.net/3db5260a62fd10ef33106bfa60f589e12a8cde7f/0096c/images/what-is-a-vector-db/random-projection.png)   
* Product Quantization(제품 양자화)   
벡터 임베딩과 비슷한 방법의 고차원 벡터 손실 압축 기술이다. 먼저 원본 벡터를 가져와서 더 작은 청크로 나누고 각 청크에 대한 대표 코드를 생성하여 각 청크의 표현을 단순화한 다음 유사성 작업에 중요한 정보를 잃지 않고 모든 청크를 다시 결합한다.   
![img](https://d33wubrfki0l68.cloudfront.net/d1c3d8b0784ab8983bf550b8332eb34de4d60b68/f717e/images/what-is-a-vector-db/product-quantization.png)   
* Loclity-sensitive hashing   
근사 최근접 이웃 검색 컨텍스트에서 인덱싱하는 기술로 속도에 최적화되어 있으면서도 대략적이고 포괄적이지 않은 결과를 제공한다.   
![img](https://d33wubrfki0l68.cloudfront.net/81ac644b41c5478c5a3114584a9ef81ab1f8b25a/3689a/images/what-is-a-vector-db/locality-sensitive-hashing.png)    
* Hierarchical Navigable Small World(HSNW)   
HSNW는 트리의 각 노드가 벡터 세트를 나타내는 계층적 트리와 같은 구조를 생성한다. 노드 사이의 모서리는 벡터 간의 유사성을 나타낸다.   
![img](https://d33wubrfki0l68.cloudfront.net/948f628e8755a5ded5ac97179c8e6ec46e5a593f/0f908/images/what-is-a-vector-db/hnsw-2.png)    

## 유사성 측정
1) 코사인 유사성   
벡터 공간에서 두 벡터 간의 각도의 코사인을 측정한다. 범위는 -1에서 1까지이며, 여기서 1은 동일한 벡터를 나타내고, 0은 직교 벡터를 나타내고, -1은 정반대의 벡터를 나타낸다.    

2) 유클리드 거리   
벡터 공간에서 두 벡터 사이의 직선 거리를 측정한다. 범위는 0에서 무한대까지이며, 여기서 0은 동일한 벡터를 나타내고 값이 클수록 점점 더 다른 벡터를 나타낸다.   

3) 내적   
두 벡터 크기의 곱과 두 벡터 사이 각도의 코사인 값을 측정한다. 범위는 -∞에서 ∞까지이며 양수 값은 같은 방향을 가리키는 벡터를 나타내고 0은 직교 벡터를 나타내고 음수 값은 반대 방향을 가리키는 벡터를 나타낸다.   

## 메타데이터 필터링
![img](https://d33wubrfki0l68.cloudfront.net/52d06478a8b85f8cea696af663a0aa39ae5adf5b/78a6c/images/what-is-a-vector-db/filtering.png)   

Post-filtering:   
벡터 검색 후에 메타데이터 필터링이 수행된다.
이렇게 하면 모든 관련 결과를 고려하는 데 도움이 될 수 있지만 검색이 완료된 후 관련 없는 결과를 필터링해야 하므로 추가 오버헤드가 발생하고 쿼리 프로세스 속도가 느려질 수도 있다.   

Pre-filtering:   
벡터 검색 전에 메타데이터 필터링이 수행된다. 이렇게 하면 검색 공간을 줄이는 데 도움이 되지만 시스템에서 메타데이터 필터 기준과 일치하지 않는 관련 결과를 간과할 수도 있다. 또한 광범위한 메타데이터 필터링으로 인해 계산 오버헤드가 추가되어 쿼리 프로세스가 느려질 수 있다.    

### 정리
- NLP, 컴퓨터 비전 및 다른 AI 어플리케이션에서 벡터 임베딩이 폭발적으로 성장하면서 벡터 데이터베이스가 등장했다.
- 프로덕션 시나리오에서 벡터 임베딩을 관리할 때 발생하는 문제점을 해결하기 위해 특수하게 만들어진게 벡터 데이터베이스는 기존의 스칼라 기반 데이터 베이스 및 스탠드얼론 벡터 인덱스에 비해 상당한 이점을 제공한다.

